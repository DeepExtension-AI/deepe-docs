
# ðŸ§  Model Training

The **Model Training** module in DeepExtension allows users to fine-tune language models through a fully visual, no-code interface. It supports various 
fine-tuning strategies, integrates seamlessly with your datasets, and provides transparent monitoring and comparison tools throughout the training 
lifecycle.

---

## ðŸš€ Start a New Train

To begin a new training job:

1. Click **"Start a New Train"**.
2. Select a fine-tuning method from those defined in [Training Method Management](training-methods.md).
3. Fill in the required parameters in the form.

| Parameter Name     | Meaning                                 | Typical Values / Range                         |
|--------------------|------------------------------------------|------------------------------------------------|
| Base Model         | The foundation model to fine-tune       | e.g., Qwen1.5-7B, Mistral, LLaMA2               |
| Dataset            | Training data to be used                | Your uploaded and labeled datasets             |
| Training Method    | Type of fine-tuning                     | LoRA, DPO, GRPO, SFT, PPO                       |
| Epochs             | Number of training iterations           | 1 â€“ 50                                         |
| Batch Size         | Samples per training step               | 2 â€“ 64                                         |
| Learning Rate      | Model update rate                       | 1e-6 â€“ 1e-3                                     |
| Max Tokens         | Max tokens per prompt                   | 512 â€“ 4096                                     |
| PEFT Config        | LoRA rank / Alpha / Dropout, etc.       | Depends on selected method                     |
| System Prompt      | Optional guide for model behavior       | Text string or left blank for default          |
| Save Frequency     | When to save checkpoints                | Every N steps or epochs                        |

Once you click **"Run the Train"**, the job will be submitted and processed in **batch mode** on your backend infrastructure.

---

## ðŸ“Š View Train Details & Monitor Progress

To inspect an existing training job:

1. Go to the **Model Training** main page.
2. Click **"View Details"** on a training job.

You will see three tabs:

- **Train Overview**: Shows all training parameters used
- **Evaluation Data**: Real-time visualizations of loss curves, reward scores, and performance metrics
- **Train Log**: Raw logs generated during training for debugging or auditing

---

## ðŸ“‹ Copy a Train

To quickly replicate and tweak a previous training job:

1. While viewing a training jobâ€™s **Train Overview** tab, scroll to the bottom.
2. Click **"Copy the Train"**.
3. This will pre-fill the new job form with the exact same configuration â€” allowing you to make minimal changes (e.g., dataset or learning rate) and run 
a comparable training job immediately.

This is ideal for A/B testing or iterative improvements.

---

## ðŸ“ˆ Training Comparison

You can compare multiple training jobs side-by-side:

- Select any two or more jobs on the main page
- Click **"Compare"** to see configuration, performance metrics, and outcomes all in one view

---

*DeepExtension â€” Simplifying the full model training lifecycle for enterprise AI*

