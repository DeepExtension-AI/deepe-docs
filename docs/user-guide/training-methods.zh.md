# 训练方法管理

**训练方法管理**模块允许您配置和注册 DeepExtension 中用于微调的大语言模型策略。这些策略可在[模型训练](model-training.zh.md)模块中选择，并定义了如何将基础模型适配到特定领域任务中。

支持的训练方法类型包括：

- **SFT**（监督式微调）
<!-- - **DPO**（直接偏好优化） -->
- **PEFT**（参数高效微调，例如 LoRA、Adapters）
- **PPO**、**GRPO** 等基于强化学习的方法

---

## 总览

在主页面的**训练方法管理**列表中，您可以看到所有已注册的训练方法。这些方法将在创建新训练任务时于[模型训练](model-training.zh.md)界面中展示。

如果您是开发者或平台维护者，请参考**开发者指南**，了解如何实现您自己的训练逻辑并将其接入 DeepExtension 平台。

---

## 添加新训练方法

要注册新的训练方法：

1. 点击 **“添加新方法”**
2. 填写以下必填信息：
   - 内部名称
   - 显示名称
   - 方法类型（例如 SFT、PEFT）
   - 方法说明
   - 可选的配置信息（如适用）

> **注意**：仅商业用户可添加新的训练方法。

> 非商业用户建议使用内置的 `custom01` 和 `custom02` 方法，这两个模板完全可定制，并可作为用户扩展逻辑的起点。具体实现请参阅**开发者指南**。

---

## 删除训练方法

要删除某个训练方法：

- 点击目标训练方法旁的 **“删除”** 按钮
- 删除后该方法将不再出现在[模型训练](model-training.zh.md)界面的可选方法列表中

> **注意**：删除功能仅对商业用户开放，以保障系统稳定性和流程完整性。

---

## 预安装的训练方法

为帮助用户快速入门，DeepExtension 根据操作系统预装了若干训练方法示例。

### Ubuntu（CUDA）用户

- **GRPO-Demo**：用于逻辑型微调任务的 GRPO（引导式强化学习）示例方法
- **SFT-Demo**：适用于小规模任务的监督式微调示例
- **Custom01** 和 **Custom02**：可由开发者扩展的完全可定制模板

### macOS 用户（适用于 MLX）

- **MLX-Demo**：基于 Apple MLX 框架的演示训练方法，专为 M 系列芯片优化
- **Custom01** 和 **Custom02**：同样提供可扩展的自定义模板

> GRPO-Demo、SFT-Demo 和 MLX-Demo 均已配置完毕，并附带示例数据集，可帮助您立即上手 DeepExtension 的训练功能。

> **Custom01** 和 **Custom02** 面向具有 AI/ML 背景的开发者设计，  
详见[实现自定义训练逻辑](../developer/implement-own-ai-training.zh.md)。

---

*DeepExtension — 灵活的训练策略管理，是实现高效微调的第一步*